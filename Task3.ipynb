{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3 - Feature Matching using SIFT\n",
    "\n",
    "Write a function which takes an image from the same dataset for training\n",
    "and testing as in the previous task.\n",
    "\n",
    "**Main steps:**\n",
    "1. You first extract keypoints and feature descriptors from your\n",
    "Test and Train images using standard SIFT or SURF feature extraction\n",
    "function from a library.\n",
    "2. Then you match features between images which will give you the raw noisy matches (correspondences).\n",
    "3. Now you should decide which geometric transform to use to reject the outliers. (using RANSAC)\n",
    "4. Finally, you will\n",
    "define a score on the obtained inlier matches and will use this to detect the\n",
    "objects (icons) scoring high for a given Test image. A basic score is counting\n",
    "the inlier matches.\n",
    "\n",
    "**Output:**\n",
    "\n",
    "Detect objects in the Test images using SIFT or equivalent features (such as SURF), recognize to which class they belong, and identify\n",
    "their scales and orientations. Similar as Task2, for visual demonstration the\n",
    "function should open a box around each detected object and indicate its class\n",
    "label. This box is scaled and rotated according to the objectâ€™s scale and orientation. Demonstrate example images(s) of the outcome detection in your report. Besides, demonstrate example images(s) that shows the feature-based\n",
    "matches established between the recognised objects and a Test image, before\n",
    "and after the outlier refinement step.\n",
    "\n",
    "**Evaluation:**\n",
    "\n",
    "Evaluate your algorithm on all Test images to report the overall Intersection over Union (IoU), False Positive (FPR), True Positive (TPR) and\n",
    "Accuracy (ACC) rates, as well as the average runtime. Refer to the following report http://host.robots.ox.ac.uk/pascal/VOC/voc2012/devkit_\n",
    "doc.pdf section 4.4 for further information about the evaluation metrics.\n",
    "Show and explain cases where this scheme finds difficulty to perform correctly. Compare the SIFT/SURF results to that of Task2 algorithm e.g.,\n",
    "does it improve the overall speed or accuracy? How much? Why?\n",
    "\n",
    "**Hyperparameter tuning:**\n",
    "\n",
    "Similarly, you will have some hyper-parameters to tune. This includes the\n",
    "number of Octaves and the (within-octave) Scalelevels within SIFT to build\n",
    "scale-spaces for keypoint detection, and the MaxRatio parameter within the\n",
    "matchFeatures function to reject weak matches. How are these parameters\n",
    "set for this task? Show quantitatively why.\n",
    "\n",
    "**Notes:**\n",
    "\n",
    "For task 2 and task 3, you are allowed to use library functions for creating the pyramid or using Gaussian convolution. You are also allowed to use the library functions for extracting features, for e.g. extracting SIFT features. You are allowed to use math libraries, for instance svd functions for computing the homography.\n",
    "\n",
    "You are *not* allowed to use the `cv2.matchTemplate` or `cv2.BFMatcher`.\n",
    "- Basically functions for matching features need to be coded. \n",
    "- You would need to implement RANSAC also yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports & Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import task3\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Integer, Real\n",
    "from skopt.utils import use_named_args\n",
    "from skopt.callbacks import Callable\n",
    "from task3 import ImageDataset, ObjectDetector, Verbosity, TutorialObjectDetector\n",
    "\n",
    "QUERY_IMG_DIR = Path(\"IconDataset\", \"png\")\n",
    "TEST_IMG_DIR = Path(\"Task3Dataset\", \"images\")\n",
    "\n",
    "ANNOTATIONS_DIR = Path(\"Task3Dataset\", \"annotations\")\n",
    "\n",
    "# Configure basic logging\n",
    "logging.basicConfig(level=logging.INFO, format='[%(asctime)s]::[%(levelname)s] %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run detection pipeline on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_on_dataset(\n",
    "        test_imgs: ImageDataset, \n",
    "        query_imgs: ImageDataset, \n",
    "        sift_hps: Dict = {},\n",
    "        ransac_hps: Dict = {},\n",
    "        lowe_threshold: float = 0.7,\n",
    "        min_match_count: int = 10, \n",
    "        verbose: Verbosity = Verbosity.MEDIUM\n",
    "    ) -> Tuple[float, ...]:\n",
    "\n",
    "    num_images = len(test_imgs)\n",
    "    acc_lst, tpr_list, fpr_lst, fnr_lst = [], [], [], []\n",
    "    detector = ObjectDetector(query_imgs, sift_hps, verbose=False, ransac_hyperparams=ransac_hps)\n",
    "\n",
    "    # Iterate through each test image and detect objects in it. Compare these detctions to the ground truth annotations.\n",
    "    for i, (img, img_path) in enumerate(test_imgs):\n",
    "        annotations_path = ANNOTATIONS_DIR / img_path.with_suffix(\".csv\").name\n",
    "        img_annotations = pd.read_csv(annotations_path)\n",
    "\n",
    "        print(flush=True); logger.info(f\"{i+1}/{num_images} - Detecting objects in {img_path.stem}\")\n",
    "        detections = detector.detect(img, lowe_threshold, min_match_count, draw=False)\n",
    "\n",
    "        acc, tpr, fpr, fnr = task3.evaluate_detections(detections, img_annotations)\n",
    "        acc_lst.append(acc); tpr_list.append(tpr); fpr_lst.append(fpr); fnr_lst.append(fnr)\n",
    "\n",
    "    return np.mean(acc_lst), np.mean(tpr_list), np.mean(fpr_lst), np.mean(fnr_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-24 18:39:26,505]::[INFO] 1/20 - Detecting objects in test_image_16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-24 18:39:37,320]::[INFO] 2/20 - Detecting objects in test_image_19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-24 18:39:47,701]::[INFO] 3/20 - Detecting objects in test_image_18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-24 18:40:00,527]::[INFO] 4/20 - Detecting objects in test_image_12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-24 18:40:11,690]::[INFO] 5/20 - Detecting objects in test_image_3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-24 18:40:25,916]::[INFO] 6/20 - Detecting objects in test_image_4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-24 18:40:37,562]::[INFO] 7/20 - Detecting objects in test_image_13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-24 18:40:47,825]::[INFO] 8/20 - Detecting objects in test_image_6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-24 18:41:03,542]::[INFO] 9/20 - Detecting objects in test_image_17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-24 18:41:11,809]::[INFO] 10/20 - Detecting objects in test_image_2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-24 18:41:21,998]::[INFO] 11/20 - Detecting objects in test_image_5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-24 18:41:34,508]::[INFO] 12/20 - Detecting objects in test_image_15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-24 18:41:47,097]::[INFO] 13/20 - Detecting objects in test_image_9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-24 18:41:54,935]::[INFO] 14/20 - Detecting objects in test_image_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-24 18:42:03,599]::[INFO] 15/20 - Detecting objects in test_image_10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-24 18:42:19,716]::[INFO] 16/20 - Detecting objects in test_image_14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-24 18:42:29,991]::[INFO] 17/20 - Detecting objects in test_image_11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-24 18:42:43,557]::[INFO] 18/20 - Detecting objects in test_image_20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-24 18:42:57,354]::[INFO] 19/20 - Detecting objects in test_image_7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-24 18:43:14,681]::[INFO] 20/20 - Detecting objects in test_image_8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5900000000000001 0.9875 0.36666666666666664 0.0125\n"
     ]
    }
   ],
   "source": [
    "test_images = ImageDataset(TEST_IMG_DIR, file_ext=\"png\")\n",
    "query_images = ImageDataset(QUERY_IMG_DIR, file_ext=\"png\")\n",
    "\n",
    "params = {\"sift_n_features\": 0, \"sift_n_octave_layers\": 10, \"sift_contrast_threshold\": 0.005, \"sift_edge_threshold\": 20.0, \"sift_sigma\": 1.9797752688667505, \"ransac_reproj_threshold\": 1.0, \"ransac_min_datapoints\": 4, \"ransac_inliers_threshold\": 0, \"ransac_confidence\": 0.9326390829908878, \"lowe_threshold\": 0.5, \"min_match_count\": 4}\n",
    "\n",
    "sift_hps = {\n",
    "        'nfeatures': params['sift_n_features'],\n",
    "        'nOctaveLayers': params['sift_n_octave_layers'],\n",
    "        'contrastThreshold': params['sift_contrast_threshold'],\n",
    "        'edgeThreshold': params['sift_edge_threshold'],\n",
    "        'sigma': params['sift_sigma'],\n",
    "    }\n",
    "\n",
    "ransac_hps = {\n",
    "    'inliers_threshold': params['ransac_inliers_threshold'],\n",
    "    'min_datapoints': params['ransac_min_datapoints'],\n",
    "    'reproj_threshold': params['ransac_reproj_threshold'],\n",
    "    'confidence': params['ransac_confidence']\n",
    "}\n",
    "\n",
    "lowe_ratio = params['lowe_threshold']\n",
    "min_match_count = params['min_match_count']\n",
    "\n",
    "\n",
    "acc, tpr, fpr, fnr = detect_on_dataset(test_images, query_images, sift_hps, ransac_hps, lowe_ratio, min_match_count)\n",
    "# acc, tpr, fpr, fnr = detect_on_dataset(test_images, query_images)\n",
    "print(acc, tpr, fpr, fnr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model                                           | acc  | tpr  | fpr  | fnr  |\n",
    "|-------------------------------------------------|------|------|------|------|\n",
    "| Mine w/ Manhattan Distance                      | 0.68 | 0.88 | 0.27 | 0.13 |\n",
    "| Mine w/ Manhattan Distance & Tuned Hyperparams  | 0.76 | 0.89 | 0.17 | 0.11 |\n",
    "| Mine w/ Euclidean Distance                      | 0.64 | 0.83 | 0.24 | 0.17 |\n",
    "| Mine w/ Euclidean Distance & Tuned Hyperparams  | 0.75 | 0.86 | 0.15 | 0.14 |\n",
    "| Mine w/ SSD                                     | 0.66 | 0.94 | 0.35 | 0.01 |\n",
    "| Tutorial w/ my matcher                          | 0.68 | 0.76 | 0.13 | 0.24 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimisation\n",
    "\n",
    "We'll use the following objective function to measure performance over a range of hyperparameters for `SIFT`, `RANSAC`, Lowe's Test, and minimum match counts. Then, using Bayesian optimisation, we'll minimise the function, hence we use '-accuracy'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_params = [\n",
    "    0, \n",
    "    3,\n",
    "    0.029251667936301906,\n",
    "    14.902523213631955,\n",
    "    1.7958084069148594,\n",
    "    1.1300029670277771,\n",
    "    4,\n",
    "    0,\n",
    "    0.9948101962008622,\n",
    "    0.6189659066006492,\n",
    "    4,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "569e1ceb9f3b495498f03a0f01541d52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sowell/projects/computer_vision/task3.py:309: RuntimeWarning: overflow encountered in scalar multiply\n",
      "  self_area = (self.right - self.left) * (self.bottom - self.top)\n",
      "/home/sowell/projects/computer_vision/task3.py:470: RuntimeWarning: invalid value encountered in cast\n",
      "  oriented_bounding_points = np.int32(destination).T.reshape(-1, 1, 2)\n",
      "/home/sowell/projects/computer_vision/task3.py:470: RuntimeWarning: invalid value encountered in cast\n",
      "  oriented_bounding_points = np.int32(destination).T.reshape(-1, 1, 2)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    \"\"\"Special json encoder for numpy types.\"\"\"\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "    \n",
    "\n",
    "class LogDisplayProgressCallback(Callable):\n",
    "\n",
    "    def __init__(self, tqdm_obj, hyperparam_names: list):\n",
    "        self.tqdm_obj = tqdm_obj\n",
    "        self.hyperparam_names = hyperparam_names\n",
    "        self.iteration = 1\n",
    "\n",
    "    def __call__(self, result):\n",
    "        self.tqdm_obj.update(1)\n",
    "\n",
    "        # Since we are minimising negative accuracy.\n",
    "        best_score = -result.fun \n",
    "        current_params = result.x\n",
    "        \n",
    "        result_data = {\n",
    "            'iteration': self.iteration,\n",
    "            'best_score': best_score,\n",
    "            'parameters': dict(zip(self.hyperparam_names, current_params))\n",
    "        }\n",
    "\n",
    "        with open('optimisation_log_ssd.json', 'a') as f:\n",
    "            json.dump(result_data, f, cls=NumpyEncoder)\n",
    "            f.write(',\\n')\n",
    "\n",
    "        self.iteration += 1\n",
    "\n",
    "\n",
    "# Define the hyperparameter space\n",
    "space = [\n",
    "    Integer(0, 164, name='sift_n_features'),\n",
    "    Integer(1, 10, name='sift_n_octave_layers'),\n",
    "    Real(0.005, 0.2, name='sift_contrast_threshold'),\n",
    "    Real(0.05, 20, name='sift_edge_threshold'),\n",
    "    Real(0.1, 5.0, name='sift_sigma'),\n",
    "    Real(1.0, 20.0, name='ransac_reproj_threshold'),\n",
    "    Integer(4, 10, name='ransac_min_datapoints'),\n",
    "    Integer(0, 8, name='ransac_inliers_threshold'),\n",
    "    Real(0.9, 1, name='ransac_confidence'),\n",
    "    Real(0.5, 2.0, name='lowe_threshold'),\n",
    "    Integer(4, 15, name='min_match_count'),\n",
    "]\n",
    "\n",
    "@use_named_args(space)\n",
    "def objective_function(**params):\n",
    "    sift_hps = {\n",
    "        'nfeatures': params['sift_n_features'],\n",
    "        'nOctaveLayers': params['sift_n_octave_layers'],\n",
    "        'contrastThreshold': params['sift_contrast_threshold'],\n",
    "        'edgeThreshold': params['sift_edge_threshold'],\n",
    "        'sigma': params['sift_sigma'],\n",
    "    }\n",
    "\n",
    "    ransac_hps = {\n",
    "        'inliers_threshold': params['ransac_inliers_threshold'],\n",
    "        'min_datapoints': params['ransac_min_datapoints'],\n",
    "        'reproj_threshold': params['ransac_reproj_threshold'],\n",
    "    }\n",
    "\n",
    "    acc, _, _, _ = detect_on_dataset(test_images, query_images, sift_hps, ransac_hps,\n",
    "                                     params['lowe_threshold'],\n",
    "                                     params['min_match_count'])\n",
    "    \n",
    "    # Negative because we minimise in the optimisation procedure.\n",
    "    return -acc\n",
    "\n",
    "\n",
    "ITERATIONS = 250\n",
    "\n",
    "tqdm_o = tqdm(total=ITERATIONS)\n",
    "callback = LogDisplayProgressCallback(tqdm_o, [param.name for param in space])\n",
    "\n",
    "test_images = ImageDataset(TEST_IMG_DIR, file_ext=\"png\")\n",
    "query_images = ImageDataset(QUERY_IMG_DIR, file_ext=\"png\")\n",
    "\n",
    "result = gp_minimize(\n",
    "    objective_function,\n",
    "    dimensions=space,\n",
    "    n_calls=ITERATIONS,\n",
    "    callback=[callback],\n",
    "    x0=[init_params]\n",
    ")\n",
    "\n",
    "tqdm_o.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
